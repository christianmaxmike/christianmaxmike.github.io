---
title: "SEA: Graph Shell Attention in Graph Neural Networks"
collection: publications
permalink: /publications/2022-03
venue: 'European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases 2022'
excerpt: 'In our work, we relax the GNN architecture by means of implementing a routing heuristic. Specifically,
the nodes’ representations are routed to dedicated experts. Each expert calculates the representations according 
to their respective GNN workflow. The definitions of distinguishable GNNs result from k-localized views starting 
from the central node. We call this procedure Graph Shell Attention (SEA), where experts process different subgraphs 
in a transformer-motivated fashion.'
date: 2022-09-19
paperurl: https://2022.ecmlpkdd.org/wp-content/uploads/2022/09/sub_803.pdf
citation: 'Frey, Christian M.M. et al., 'SEA: Graph Shell Attention in Graph Neural Networks', European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases 2022<br/>'
---

## Abstract
A common problem in Graph Neural Networks (GNNs) is
known as over-smoothing. By increasing the number of iterations within
the message-passing of GNNs, the nodes’ representations of the input
graph align and become indiscernible. The latest models employing at-
tention mechanisms with Graph Transformer Layers (GTLs) are still
restricted to the layer-wise computational workflow of a GNN that are
not beyond preventing such effects. In our work, we relax the GNN ar-
chitecture by means of implementing a routing heuristic. Specifically,
the nodes’ representations are routed to dedicated experts. Each expert
calculates the representations according to their respective GNN work-
flow. The definitions of distinguishable GNNs result from k-localized
views starting from the central node. We call this procedure Graph
Shell Attention (SEA), where experts process different subgraphs in a
transformer-motivated fashion. Intuitively, by increasing the number of
experts, the models gain in expressiveness such that a node’s representa-
tion is solely based on nodes that are located within the receptive field of
an expert. We evaluate our architecture on various benchmark datasets
showing competitive results while drastically reducing the number of pa-
rameters compared to state-of-the-art models.
